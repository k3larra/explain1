### Comparing Grad-Cam explanations with human explanations 

This is a site supports the paper "Breaking out of the interpretability asylum using social sciences and coffee plates as battering ram." with code and data in the form of images. The code can be found in the file code.ipynb and images used are in the compressed file images/data_2.zip.

We use an implementation of [GradCam](https://github.com/anhquan0412/animation-classification) by Quan Tran. GradCam produces visual explanations of individual classifications by highlighting areas central to the decision making. 

Read more about GradCam in the paper "Grad-cam: Visual explanations from deep networks via gradient-based localization" written by Selvaju et al.

ML framework used: [Fast.ai](fast.ai) that builds on PyTorch. 
